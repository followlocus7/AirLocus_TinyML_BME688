{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035a0b29-151e-4d0c-b4e4-6642c3d33b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv generated with 1000 samples!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "num_samples = 1000\n",
    "\n",
    "# Input features\n",
    "temp_C = np.random.uniform(15, 40, num_samples)          # 15°C to 40°C\n",
    "humidity_pct = np.random.uniform(20, 90, num_samples)    # 20% to 90%\n",
    "pressure_hPa = np.random.uniform(950, 1050, num_samples) # 950 hPa to 1050 hPa\n",
    "gas_res_ohm = np.random.uniform(100, 1000, num_samples)  # 100Ω to 1000Ω\n",
    "\n",
    "# Gas concentrations (synthetic)\n",
    "co_ppm = 0.5 * temp_C + 0.3 * humidity_pct + np.random.normal(0, 5, num_samples)\n",
    "co2_ppm = 10 * np.log1p(temp_C) + 0.2 * pressure_hPa + np.random.normal(0, 10, num_samples)\n",
    "so2_ppm = 0.05 * gas_res_ohm + np.random.normal(0, 2, num_samples)\n",
    "no2_ppm = 0.1 * humidity_pct + 0.02 * pressure_hPa + np.random.normal(0, 3, num_samples)\n",
    "ch4_ppm = 0.01 * gas_res_ohm + 0.5 * temp_C + np.random.normal(0, 1, num_samples)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'temp_C': temp_C,\n",
    "    'humidity_pct': humidity_pct,\n",
    "    'pressure_hPa': pressure_hPa,\n",
    "    'gas_res_ohm': gas_res_ohm,\n",
    "    'co_ppm': co_ppm,\n",
    "    'co2_ppm': co2_ppm,\n",
    "    'so2_ppm': so2_ppm,\n",
    "    'no2_ppm': no2_ppm,\n",
    "    'ch4_ppm': ch4_ppm\n",
    "})\n",
    "\n",
    "# Save to CSV in the same folder as notebook\n",
    "df.to_csv('train.csv', index=False)\n",
    "print(\"train.csv generated with 1000 samples!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7bb93f6-b35a-40ec-9ae0-a162e725a86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler parameters saved.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11366.9678 - mae: 66.6682 - val_loss: 11207.8320 - val_mae: 66.3985\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11072.6533 - mae: 65.5728 - val_loss: 10750.3525 - val_mae: 64.4282\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10425.9082 - mae: 62.4267 - val_loss: 9810.2188 - val_mae: 59.3825\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9228.3955 - mae: 55.6372 - val_loss: 8258.3994 - val_mae: 50.0990\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7484.8228 - mae: 46.2482 - val_loss: 6304.8994 - val_mae: 42.2028\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5464.0137 - mae: 39.4032 - val_loss: 4215.5918 - val_mae: 35.4259\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3393.7754 - mae: 31.4492 - val_loss: 2287.0320 - val_mae: 26.3796\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1680.9731 - mae: 22.4097 - val_loss: 968.3023 - val_mae: 17.5332\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 690.1113 - mae: 14.8641 - val_loss: 426.2931 - val_mae: 12.4225\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 346.4916 - mae: 11.3379 - val_loss: 308.6566 - val_mae: 10.9157\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 279.3202 - mae: 10.4904 - val_loss: 288.8485 - val_mae: 10.6392\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.6118 - mae: 10.3194 - val_loss: 276.5079 - val_mae: 10.4600\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 256.4548 - mae: 10.1779 - val_loss: 267.8534 - val_mae: 10.3034\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 248.7480 - mae: 10.0347 - val_loss: 260.7769 - val_mae: 10.1611\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.2366 - mae: 9.8739 - val_loss: 253.8555 - val_mae: 9.9941\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.7410 - mae: 9.6969 - val_loss: 246.8271 - val_mae: 9.8256\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 225.5451 - mae: 9.4993 - val_loss: 238.5118 - val_mae: 9.6306\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.5454 - mae: 9.3066 - val_loss: 230.7326 - val_mae: 9.4409\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 209.6723 - mae: 9.1039 - val_loss: 223.3202 - val_mae: 9.2379\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 202.2186 - mae: 8.8843 - val_loss: 216.4616 - val_mae: 9.0282\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 194.4992 - mae: 8.6814 - val_loss: 209.3351 - val_mae: 8.8060\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 187.4590 - mae: 8.4717 - val_loss: 202.0714 - val_mae: 8.6373\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 180.5733 - mae: 8.2527 - val_loss: 194.9929 - val_mae: 8.4098\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 173.8770 - mae: 8.0564 - val_loss: 188.4272 - val_mae: 8.2312\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167.0912 - mae: 7.8565 - val_loss: 181.2227 - val_mae: 8.0443\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160.8790 - mae: 7.6610 - val_loss: 176.0945 - val_mae: 7.8279\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 155.1192 - mae: 7.4715 - val_loss: 168.6061 - val_mae: 7.6627\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 149.7693 - mae: 7.3091 - val_loss: 164.0730 - val_mae: 7.5190\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 143.7424 - mae: 7.1221 - val_loss: 158.1839 - val_mae: 7.3253\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138.8599 - mae: 6.9726 - val_loss: 153.0189 - val_mae: 7.1886\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133.7554 - mae: 6.8310 - val_loss: 146.9747 - val_mae: 7.0294\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 128.8438 - mae: 6.6976 - val_loss: 141.5425 - val_mae: 6.8739\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124.1752 - mae: 6.5668 - val_loss: 138.1174 - val_mae: 6.7691\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.4973 - mae: 6.4310 - val_loss: 132.2208 - val_mae: 6.6149\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.5788 - mae: 6.3320 - val_loss: 127.6934 - val_mae: 6.5064\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.2298 - mae: 6.2062 - val_loss: 123.5356 - val_mae: 6.3902\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 107.2144 - mae: 6.1072 - val_loss: 119.3283 - val_mae: 6.3528\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 102.9542 - mae: 5.9905 - val_loss: 113.5841 - val_mae: 6.1251\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 99.2142 - mae: 5.8778 - val_loss: 110.7347 - val_mae: 6.0568\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 95.1156 - mae: 5.7569 - val_loss: 106.2572 - val_mae: 5.9220\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 91.6796 - mae: 5.6651 - val_loss: 102.7786 - val_mae: 5.8224\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 88.2339 - mae: 5.5699 - val_loss: 98.4901 - val_mae: 5.7338\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 85.1844 - mae: 5.4750 - val_loss: 95.4922 - val_mae: 5.6196\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82.1550 - mae: 5.3818 - val_loss: 92.1163 - val_mae: 5.5142\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 79.1430 - mae: 5.2884 - val_loss: 89.3964 - val_mae: 5.4378\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.2033 - mae: 5.1909 - val_loss: 85.3682 - val_mae: 5.3041\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.6433 - mae: 5.1161 - val_loss: 82.3114 - val_mae: 5.2326\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71.1254 - mae: 5.0325 - val_loss: 79.5065 - val_mae: 5.1461\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.5248 - mae: 4.9478 - val_loss: 76.9344 - val_mae: 5.0610\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.3493 - mae: 4.8725 - val_loss: 74.4489 - val_mae: 4.9583\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.9330 - mae: 4.7901 - val_loss: 71.4939 - val_mae: 4.8765\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 61.8869 - mae: 4.7287 - val_loss: 69.6617 - val_mae: 4.8274\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.7560 - mae: 4.6518 - val_loss: 67.3715 - val_mae: 4.7405\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.9117 - mae: 4.5880 - val_loss: 65.2044 - val_mae: 4.6757\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.1825 - mae: 4.5278 - val_loss: 62.8647 - val_mae: 4.5983\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 54.7071 - mae: 4.4856 - val_loss: 60.9869 - val_mae: 4.5462\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 53.1733 - mae: 4.4290 - val_loss: 60.2273 - val_mae: 4.5039\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 51.7034 - mae: 4.3758 - val_loss: 57.9477 - val_mae: 4.4551\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.2071 - mae: 4.3177 - val_loss: 56.6419 - val_mae: 4.4002\n",
      "Epoch 60/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.9958 - mae: 4.2745 - val_loss: 54.8986 - val_mae: 4.3519\n",
      "Epoch 61/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 47.6534 - mae: 4.2284 - val_loss: 53.7683 - val_mae: 4.3258\n",
      "Epoch 62/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.5750 - mae: 4.1877 - val_loss: 52.1996 - val_mae: 4.2578\n",
      "Epoch 63/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45.7565 - mae: 4.1627 - val_loss: 51.0719 - val_mae: 4.2153\n",
      "Epoch 64/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.7908 - mae: 4.1274 - val_loss: 50.2824 - val_mae: 4.1954\n",
      "Epoch 65/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.8411 - mae: 4.0795 - val_loss: 48.9640 - val_mae: 4.1461\n",
      "Epoch 66/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.9488 - mae: 4.0639 - val_loss: 47.9478 - val_mae: 4.1398\n",
      "Epoch 67/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.0514 - mae: 4.0206 - val_loss: 47.1435 - val_mae: 4.1096\n",
      "Epoch 68/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.4546 - mae: 3.9994 - val_loss: 46.2336 - val_mae: 4.0848\n",
      "Epoch 69/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.7216 - mae: 3.9718 - val_loss: 45.5657 - val_mae: 4.0668\n",
      "Epoch 70/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.0091 - mae: 3.9469 - val_loss: 44.5431 - val_mae: 4.0033\n",
      "Epoch 71/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.4144 - mae: 3.9218 - val_loss: 44.1659 - val_mae: 4.0085\n",
      "Epoch 72/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.9308 - mae: 3.9028 - val_loss: 42.9555 - val_mae: 3.9432\n",
      "Epoch 73/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.2679 - mae: 3.8746 - val_loss: 42.2155 - val_mae: 3.9196\n",
      "Epoch 74/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37.6952 - mae: 3.8544 - val_loss: 41.7966 - val_mae: 3.9078\n",
      "Epoch 75/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37.1792 - mae: 3.8324 - val_loss: 41.1411 - val_mae: 3.8967\n",
      "Epoch 76/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.5998 - mae: 3.8077 - val_loss: 40.5029 - val_mae: 3.8761\n",
      "Epoch 77/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.2648 - mae: 3.7988 - val_loss: 40.0090 - val_mae: 3.8707\n",
      "Epoch 78/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.9162 - mae: 3.7954 - val_loss: 39.3725 - val_mae: 3.8208\n",
      "Epoch 79/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.3992 - mae: 3.7627 - val_loss: 38.9119 - val_mae: 3.8136\n",
      "Epoch 80/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.9340 - mae: 3.7519 - val_loss: 38.3180 - val_mae: 3.7732\n",
      "Epoch 81/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.7141 - mae: 3.7357 - val_loss: 37.9971 - val_mae: 3.7822\n",
      "Epoch 82/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.2672 - mae: 3.7245 - val_loss: 37.4353 - val_mae: 3.7467\n",
      "Epoch 83/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.8797 - mae: 3.7025 - val_loss: 37.1071 - val_mae: 3.7267\n",
      "Epoch 84/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.5278 - mae: 3.6822 - val_loss: 36.8713 - val_mae: 3.7456\n",
      "Epoch 85/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.2292 - mae: 3.6683 - val_loss: 36.1628 - val_mae: 3.7112\n",
      "Epoch 86/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.2761 - mae: 3.6681 - val_loss: 36.2984 - val_mae: 3.7125\n",
      "Epoch 87/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.8993 - mae: 3.6523 - val_loss: 35.5167 - val_mae: 3.6782\n",
      "Epoch 88/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.5229 - mae: 3.6456 - val_loss: 35.3003 - val_mae: 3.6684\n",
      "Epoch 89/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.2633 - mae: 3.6171 - val_loss: 35.0574 - val_mae: 3.6742\n",
      "Epoch 90/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.0285 - mae: 3.6195 - val_loss: 34.9118 - val_mae: 3.6788\n",
      "Epoch 91/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.7660 - mae: 3.5992 - val_loss: 34.7333 - val_mae: 3.6599\n",
      "Epoch 92/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.6035 - mae: 3.5976 - val_loss: 34.5733 - val_mae: 3.6359\n",
      "Epoch 93/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.2922 - mae: 3.5800 - val_loss: 33.8912 - val_mae: 3.6224\n",
      "Epoch 94/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.1824 - mae: 3.5815 - val_loss: 33.9956 - val_mae: 3.6474\n",
      "Epoch 95/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.1660 - mae: 3.5691 - val_loss: 34.2083 - val_mae: 3.6610\n",
      "Epoch 96/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.0643 - mae: 3.5765 - val_loss: 33.8117 - val_mae: 3.6273\n",
      "Epoch 97/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.8997 - mae: 3.5767 - val_loss: 33.0923 - val_mae: 3.5951\n",
      "Epoch 98/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.5941 - mae: 3.5542 - val_loss: 33.4955 - val_mae: 3.6412\n",
      "Epoch 99/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.5062 - mae: 3.5396 - val_loss: 32.9044 - val_mae: 3.5803\n",
      "Epoch 100/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.5106 - mae: 3.5441 - val_loss: 32.8463 - val_mae: 3.5733\n",
      "Keras model saved: gas_model.keras\n",
      "Saved artifact at 'C:\\Users\\SAIGAN~1\\AppData\\Local\\Temp\\tmpqbgqq5ao'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 4), dtype=tf.float32, name='keras_tensor_32')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2165873876368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2165912899792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2165873876752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2165873878288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2165912908624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2165912909776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "TFLite model saved: gas_model_int8.tflite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress TF, absl, and warnings\n",
    "# -----------------------------\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # hide TF info/warnings\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# -----------------------------\n",
    "# Imports\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"train.csv\")  # ensure this is in the same folder\n",
    "\n",
    "feature_cols = ['temp_C','humidity_pct','pressure_hPa','gas_res_ohm']\n",
    "target_cols = ['co_ppm','co2_ppm','so2_ppm','no2_ppm','ch4_ppm']\n",
    "\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "y = df[target_cols].values.astype(np.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Split dataset\n",
    "# -----------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Scale inputs\n",
    "# -----------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Save scaler params for MCU\n",
    "np.savez(\"scaler_params.npz\", mean=scaler.mean_, scale=scaler.scale_)\n",
    "print(\"Scaler parameters saved.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Build model\n",
    "# -----------------------------\n",
    "inputs = tf.keras.Input(shape=(X_train_scaled.shape[1],))\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(len(target_cols), activation='linear')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Hide model.summary() output for clean console\n",
    "model.summary(print_fn=lambda x: None)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Train model\n",
    "# -----------------------------\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Save Keras model\n",
    "# -----------------------------\n",
    "model.save(\"gas_model.keras\")  # use native Keras format to avoid HDF5 warnings\n",
    "print(\"Keras model saved: gas_model.keras\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Convert to TFLite (integer quantization)\n",
    "# -----------------------------\n",
    "def representative_data_gen():\n",
    "    for i in range(min(1000, X_train_scaled.shape[0])):\n",
    "        sample = X_train_scaled[i:i+1].astype(np.float32)\n",
    "        yield [sample]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(\"gas_model_int8.tflite\",\"wb\").write(tflite_model)\n",
    "print(\"TFLite model saved: gas_model_int8.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bcfbe06-9a0e-4e4b-8893-f1ad1518c6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Predicted gas values: [ 27.195318 228.64212   25.18085   24.173615  17.122978]\n",
      "Sample 2: Predicted gas values: [ 26.188084 230.65659   26.188084  24.173615  17.122978]\n",
      "Sample 3: Predicted gas values: [ 28.20255  227.63487   25.18085   25.18085   16.115744]\n",
      "Sample 4: Predicted gas values: [ 31.224253 229.64935   26.188084  26.188084  18.13021 ]\n",
      "Sample 5: Predicted gas values: [ 23.166382 227.63487   24.173615  23.166382  15.10851 ]\n",
      "Sample 6: Predicted gas values: [ 33.23872  230.65659   27.195318  26.188084  19.137445]\n",
      "Sample 7: Predicted gas values: [ 26.188084 227.63487   24.173615  24.173615  15.10851 ]\n",
      "Sample 8: Predicted gas values: [ 31.224253 230.65659   27.195318  25.18085   19.137445]\n",
      "Sample 9: Predicted gas values: [ 24.173615 226.62764   23.166382  23.166382  15.10851 ]\n",
      "Sample 10: Predicted gas values: [ 33.23872  232.67105   28.20255   26.188084  20.14468 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"gas_model_int8.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load scaler parameters\n",
    "scaler_params = np.load(\"scaler_params.npz\")\n",
    "mean = scaler_params[\"mean\"]\n",
    "scale = scaler_params[\"scale\"]\n",
    "\n",
    "# Sample inputs\n",
    "sample_inputs = np.array([\n",
    "    [25.0, 50.0, 1000.0, 500.0],\n",
    "    [26.0, 45.0, 1005.0, 520.0],\n",
    "    [24.5, 55.0, 995.0, 510.0],\n",
    "    [27.0, 60.0, 1002.0, 530.0],\n",
    "    [23.0, 40.0, 998.0, 480.0],\n",
    "    [28.0, 65.0, 1008.0, 540.0],\n",
    "    [22.0, 50.0, 1001.0, 495.0],\n",
    "    [29.0, 55.0, 1003.0, 550.0],\n",
    "    [21.0, 45.0, 997.0, 470.0],\n",
    "    [30.0, 60.0, 1010.0, 560.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Run inference for each sample\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "output_scale, output_zero_point = output_details[0][\"quantization\"]\n",
    "\n",
    "for i, sample_raw in enumerate(sample_inputs):\n",
    "    # Scale\n",
    "    sample_scaled = (sample_raw - mean) / scale\n",
    "    # Quantize\n",
    "    sample_int8 = (sample_scaled / input_scale + input_zero_point).astype(np.int8)\n",
    "    sample_int8 = sample_int8.reshape(1, -1)  # batch size 1\n",
    "\n",
    "    # Set input and invoke\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], sample_int8)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get output and dequantize\n",
    "    output_int8 = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    output_float = (output_int8.astype(np.float32) - output_zero_point) * output_scale\n",
    "\n",
    "    print(f\"Sample {i+1}: Predicted gas values: {output_float[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "261424da-2bf9-42a4-8e80-bb76e6f1a05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C array file generated successfully: gas_model_int8.cc\n",
      "File size: 10536 bytes\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_model_file = \"gas_model_int8.tflite\"\n",
    "c_array_file = \"gas_model_int8.cc\"\n",
    "\n",
    "tflite_model = pathlib.Path(tflite_model_file).read_bytes()\n",
    "with open(c_array_file, \"w\") as f:\n",
    "    f.write(\"const unsigned char g_gas_model[] = {\")\n",
    "    for i, byte in enumerate(tflite_model):\n",
    "        if i % 12 == 0:\n",
    "            f.write(\"\\n  \")\n",
    "        f.write(f\"0x{byte:02x}, \")\n",
    "    f.write(\"\\n};\\n\")\n",
    "    f.write(f\"const int g_gas_model_len = {len(tflite_model)};\\n\")\n",
    "\n",
    "print(f\"C array file generated successfully: {c_array_file}\")\n",
    "print(f\"File size: {len(tflite_model)} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080af3e-2a64-4cc6-bb80-5562d4723459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
