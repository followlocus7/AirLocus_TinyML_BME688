{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d183f8-a882-4241-b091-d64aa85b2d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv generated with 1000 samples!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "num_samples = 1000\n",
    "\n",
    "# Input features\n",
    "temp_C = np.random.uniform(15, 40, num_samples)          # 15°C to 40°C\n",
    "humidity_pct = np.random.uniform(20, 90, num_samples)    # 20% to 90%\n",
    "pressure_hPa = np.random.uniform(950, 1050, num_samples) # 950 hPa to 1050 hPa\n",
    "gas_res_ohm = np.random.uniform(100, 1000, num_samples)  # 100Ω to 1000Ω\n",
    "\n",
    "# Gas concentrations (synthetic)\n",
    "co_ppm = 0.5 * temp_C + 0.3 * humidity_pct + np.random.normal(0, 5, num_samples)\n",
    "co2_ppm = 10 * np.log1p(temp_C) + 0.2 * pressure_hPa + np.random.normal(0, 10, num_samples)\n",
    "so2_ppm = 0.05 * gas_res_ohm + np.random.normal(0, 2, num_samples)\n",
    "no2_ppm = 0.1 * humidity_pct + 0.02 * pressure_hPa + np.random.normal(0, 3, num_samples)\n",
    "ch4_ppm = 0.01 * gas_res_ohm + 0.5 * temp_C + np.random.normal(0, 1, num_samples)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'temp_C': temp_C,\n",
    "    'humidity_pct': humidity_pct,\n",
    "    'pressure_hPa': pressure_hPa,\n",
    "    'gas_res_ohm': gas_res_ohm,\n",
    "    'co_ppm': co_ppm,\n",
    "    'co2_ppm': co2_ppm,\n",
    "    'so2_ppm': so2_ppm,\n",
    "    'no2_ppm': no2_ppm,\n",
    "    'ch4_ppm': ch4_ppm\n",
    "})\n",
    "\n",
    "# Save to CSV in the same folder as notebook\n",
    "df.to_csv('train.csv', index=False)\n",
    "print(\"train.csv generated with 1000 samples!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86faff1-8803-4138-a85b-58e03e6c9853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler parameters saved.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,805</span> (18.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,805\u001b[0m (18.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,805</span> (18.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,805\u001b[0m (18.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 11379.2334 - mae: 66.6304 - val_loss: 11246.3672 - val_mae: 66.4099\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11131.4033 - mae: 65.5964 - val_loss: 10842.0020 - val_mae: 64.4579\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10525.7461 - mae: 62.3357 - val_loss: 9951.2988 - val_mae: 59.2528\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9366.4658 - mae: 55.2399 - val_loss: 8460.7607 - val_mae: 49.8577\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7683.4277 - mae: 45.7914 - val_loss: 6601.1294 - val_mae: 42.1215\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5763.0527 - mae: 40.1627 - val_loss: 4618.5967 - val_mae: 37.1478\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3737.4058 - mae: 33.3318 - val_loss: 2638.7529 - val_mae: 28.2986\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1928.1207 - mae: 24.2026 - val_loss: 1167.8765 - val_mae: 19.2661\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 789.8284 - mae: 16.0927 - val_loss: 488.4032 - val_mae: 13.1253\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 358.4696 - mae: 11.5090 - val_loss: 324.3220 - val_mae: 11.0339\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 270.5654 - mae: 10.4719 - val_loss: 302.6188 - val_mae: 10.6738\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 254.1886 - mae: 10.1903 - val_loss: 289.9559 - val_mae: 10.4081\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 243.6053 - mae: 9.9472 - val_loss: 277.5551 - val_mae: 10.1428\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 233.8214 - mae: 9.7140 - val_loss: 266.7059 - val_mae: 9.8644\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 224.7125 - mae: 9.4302 - val_loss: 255.4622 - val_mae: 9.6060\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 215.0760 - mae: 9.1606 - val_loss: 245.8125 - val_mae: 9.3395\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 206.6146 - mae: 8.8847 - val_loss: 237.9934 - val_mae: 9.1902\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 198.6610 - mae: 8.6487 - val_loss: 229.0405 - val_mae: 8.9146\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 190.9508 - mae: 8.3876 - val_loss: 220.8357 - val_mae: 8.6884\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 183.7628 - mae: 8.1513 - val_loss: 211.5504 - val_mae: 8.4517\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 177.1749 - mae: 7.9270 - val_loss: 204.0860 - val_mae: 8.2221\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 170.7009 - mae: 7.7013 - val_loss: 197.5232 - val_mae: 8.0315\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 164.4404 - mae: 7.4964 - val_loss: 189.8726 - val_mae: 7.7972\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 158.9813 - mae: 7.2903 - val_loss: 183.0884 - val_mae: 7.6131\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 153.3829 - mae: 7.1269 - val_loss: 177.5034 - val_mae: 7.4507\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 148.0953 - mae: 6.9644 - val_loss: 171.0946 - val_mae: 7.2666\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 143.6527 - mae: 6.8457 - val_loss: 165.6230 - val_mae: 7.1525\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 138.3369 - mae: 6.6924 - val_loss: 161.0241 - val_mae: 7.0043\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 133.8940 - mae: 6.5697 - val_loss: 155.0477 - val_mae: 6.8933\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 129.3857 - mae: 6.4454 - val_loss: 149.7549 - val_mae: 6.7455\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 125.1732 - mae: 6.3390 - val_loss: 144.5709 - val_mae: 6.6306\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 121.0186 - mae: 6.2501 - val_loss: 140.3292 - val_mae: 6.5371\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 116.8556 - mae: 6.1267 - val_loss: 135.8893 - val_mae: 6.4123\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 113.1211 - mae: 6.0454 - val_loss: 131.0278 - val_mae: 6.3118\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 108.9817 - mae: 5.9421 - val_loss: 126.1153 - val_mae: 6.2265\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 105.5472 - mae: 5.8525 - val_loss: 123.3460 - val_mae: 6.1392\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 101.4932 - mae: 5.7730 - val_loss: 117.7795 - val_mae: 6.0351\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 98.1419 - mae: 5.6790 - val_loss: 113.4373 - val_mae: 5.9444\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 94.6720 - mae: 5.6003 - val_loss: 110.4071 - val_mae: 5.8706\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 91.2095 - mae: 5.5160 - val_loss: 106.0496 - val_mae: 5.7696\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 87.9007 - mae: 5.4273 - val_loss: 102.4457 - val_mae: 5.6953\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 84.9731 - mae: 5.3523 - val_loss: 98.3696 - val_mae: 5.5985\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 82.0604 - mae: 5.2822 - val_loss: 96.5243 - val_mae: 5.5376\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 79.0278 - mae: 5.1945 - val_loss: 92.2878 - val_mae: 5.4408\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 76.6496 - mae: 5.1148 - val_loss: 88.4037 - val_mae: 5.3425\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 73.7954 - mae: 5.0574 - val_loss: 85.5694 - val_mae: 5.2863\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 71.0374 - mae: 4.9738 - val_loss: 83.4932 - val_mae: 5.2085\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 68.5815 - mae: 4.8955 - val_loss: 79.8530 - val_mae: 5.1295\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 66.3466 - mae: 4.8340 - val_loss: 77.7892 - val_mae: 5.0749\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 64.1142 - mae: 4.7688 - val_loss: 74.8608 - val_mae: 4.9908\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 62.0751 - mae: 4.6977 - val_loss: 72.8528 - val_mae: 4.9296\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 60.2827 - mae: 4.6442 - val_loss: 69.9388 - val_mae: 4.8464\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 58.3744 - mae: 4.5887 - val_loss: 68.9777 - val_mae: 4.8302\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 56.4666 - mae: 4.5303 - val_loss: 65.6199 - val_mae: 4.7237\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54.8880 - mae: 4.4856 - val_loss: 63.7938 - val_mae: 4.6515\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 53.2236 - mae: 4.4154 - val_loss: 61.9951 - val_mae: 4.5999\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 51.6527 - mae: 4.3711 - val_loss: 60.5491 - val_mae: 4.5553\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 50.5294 - mae: 4.3286 - val_loss: 58.3566 - val_mae: 4.4726\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 48.8779 - mae: 4.2651 - val_loss: 56.7947 - val_mae: 4.4213\n",
      "Epoch 60/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 47.7166 - mae: 4.2264 - val_loss: 55.4381 - val_mae: 4.3750\n",
      "Epoch 61/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 46.6032 - mae: 4.1892 - val_loss: 54.1508 - val_mae: 4.3169\n",
      "Epoch 62/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.5315 - mae: 4.1431 - val_loss: 52.2014 - val_mae: 4.2663\n",
      "Epoch 63/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 44.5881 - mae: 4.1203 - val_loss: 51.4488 - val_mae: 4.2370\n",
      "Epoch 64/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 43.6243 - mae: 4.0834 - val_loss: 49.7397 - val_mae: 4.1953\n",
      "Epoch 65/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 42.6488 - mae: 4.0483 - val_loss: 48.9737 - val_mae: 4.1523\n",
      "Epoch 66/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 41.7666 - mae: 4.0122 - val_loss: 47.6108 - val_mae: 4.1265\n",
      "Epoch 67/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 40.9965 - mae: 3.9811 - val_loss: 47.2209 - val_mae: 4.1013\n",
      "Epoch 68/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 40.2561 - mae: 3.9503 - val_loss: 45.6952 - val_mae: 4.0403\n",
      "Epoch 69/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 39.7138 - mae: 3.9423 - val_loss: 44.9292 - val_mae: 4.0248\n",
      "Epoch 70/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 38.8717 - mae: 3.8985 - val_loss: 43.7335 - val_mae: 3.9954\n",
      "Epoch 71/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 38.4423 - mae: 3.8863 - val_loss: 43.1620 - val_mae: 3.9830\n",
      "Epoch 72/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.6887 - mae: 3.8497 - val_loss: 42.5644 - val_mae: 3.9341\n",
      "Epoch 73/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.1635 - mae: 3.8391 - val_loss: 41.4976 - val_mae: 3.9021\n",
      "Epoch 74/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.5876 - mae: 3.8171 - val_loss: 40.8405 - val_mae: 3.8957\n",
      "Epoch 75/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.1331 - mae: 3.8060 - val_loss: 40.3117 - val_mae: 3.8634\n",
      "Epoch 76/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 35.6509 - mae: 3.7773 - val_loss: 39.4468 - val_mae: 3.8234\n",
      "Epoch 77/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.2264 - mae: 3.7638 - val_loss: 39.1157 - val_mae: 3.8173\n",
      "Epoch 78/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 34.9350 - mae: 3.7458 - val_loss: 38.7078 - val_mae: 3.7932\n",
      "Epoch 79/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 34.5271 - mae: 3.7328 - val_loss: 38.2682 - val_mae: 3.7931\n",
      "Epoch 80/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.2976 - mae: 3.7217 - val_loss: 37.4183 - val_mae: 3.7588\n",
      "Epoch 81/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 33.9399 - mae: 3.7054 - val_loss: 36.9458 - val_mae: 3.7452\n",
      "Epoch 82/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 33.6511 - mae: 3.6968 - val_loss: 36.8229 - val_mae: 3.7354\n",
      "Epoch 83/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.4037 - mae: 3.6838 - val_loss: 36.4947 - val_mae: 3.7160\n",
      "Epoch 84/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 33.0439 - mae: 3.6609 - val_loss: 35.9090 - val_mae: 3.6973\n",
      "Epoch 85/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 32.6371 - mae: 3.6492 - val_loss: 35.8112 - val_mae: 3.7090\n",
      "Epoch 86/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.5889 - mae: 3.6464 - val_loss: 35.5758 - val_mae: 3.7110\n",
      "Epoch 87/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 32.4042 - mae: 3.6352 - val_loss: 34.9752 - val_mae: 3.6639\n",
      "Epoch 88/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.2215 - mae: 3.6271 - val_loss: 34.7244 - val_mae: 3.6744\n",
      "Epoch 89/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.8677 - mae: 3.6137 - val_loss: 34.5146 - val_mae: 3.6430\n",
      "Epoch 90/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.6690 - mae: 3.6048 - val_loss: 34.1886 - val_mae: 3.6612\n",
      "Epoch 91/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.5043 - mae: 3.5951 - val_loss: 34.1330 - val_mae: 3.6327\n",
      "Epoch 92/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.3126 - mae: 3.5817 - val_loss: 33.7049 - val_mae: 3.6147\n",
      "Epoch 93/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.2496 - mae: 3.5739 - val_loss: 33.5752 - val_mae: 3.6128\n",
      "Epoch 94/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.1527 - mae: 3.5779 - val_loss: 33.5258 - val_mae: 3.6209\n",
      "Epoch 95/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.0149 - mae: 3.5675 - val_loss: 33.3089 - val_mae: 3.5934\n",
      "Epoch 96/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.9151 - mae: 3.5618 - val_loss: 32.8793 - val_mae: 3.5918\n",
      "Epoch 97/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7461 - mae: 3.5523 - val_loss: 32.8975 - val_mae: 3.5928\n",
      "Epoch 98/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7628 - mae: 3.5639 - val_loss: 32.8197 - val_mae: 3.6354\n",
      "Epoch 99/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5757 - mae: 3.5487 - val_loss: 32.4942 - val_mae: 3.5651\n",
      "Epoch 100/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.5566 - mae: 3.5465 - val_loss: 32.5045 - val_mae: 3.5851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model saved: gas_model.h5\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\SAIGAN~1\\AppData\\Local\\Temp\\tmp96uwa0u2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\SAIGAN~1\\AppData\\Local\\Temp\\tmp96uwa0u2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\SAIGAN~1\\AppData\\Local\\Temp\\tmp96uwa0u2'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 4), dtype=tf.float32, name='keras_tensor_4')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1837959035984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1837980737488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1837959034640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1837980737296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1837980739216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1837980742480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sai ganesh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model saved: gas_model_int8.tflite\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 2. Load dataset\n",
    "df = pd.read_csv(\"train.csv\")  # make sure it's in the same folder\n",
    "\n",
    "feature_cols = ['temp_C','humidity_pct','pressure_hPa','gas_res_ohm']\n",
    "target_cols = ['co_ppm','co2_ppm','so2_ppm','no2_ppm','ch4_ppm']\n",
    "\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "y = df[target_cols].values.astype(np.float32)\n",
    "\n",
    "# 3. Split dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# 4. Scale inputs\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Save scaler params for MCU\n",
    "np.savez(\"scaler_params.npz\", mean=scaler.mean_, scale=scaler.scale_)\n",
    "print(\"Scaler parameters saved.\")\n",
    "\n",
    "# 5. Build model\n",
    "inputs = tf.keras.Input(shape=(X_train_scaled.shape[1],))\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(len(target_cols), activation='linear')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# 6. Train model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 7. Save Keras model\n",
    "model.save(\"gas_model.h5\")\n",
    "print(\"Keras model saved: gas_model.h5\")\n",
    "\n",
    "# 8. Convert to TFLite (full integer quantization)\n",
    "def representative_data_gen():\n",
    "    for i in range(min(1000, X_train_scaled.shape[0])):\n",
    "        sample = X_train_scaled[i:i+1].astype(np.float32)\n",
    "        yield [sample]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(\"gas_model_int8.tflite\",\"wb\").write(tflite_model)\n",
    "print(\"TFLite model saved: gas_model_int8.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68191a1d-91a7-4104-a2f9-f3806e71ff5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sai ganesh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"gas_model_int8.tflite\")\n",
    "interpreter.allocate_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862b9b50-7f1e-4dc9-8c74-ecdbcadda135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_keras_tensor_4:0', 'index': 0, 'shape': array([1, 4], dtype=int32), 'shape_signature': array([-1,  4], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.013899932615458965, -2), 'quantization_parameters': {'scales': array([0.01389993], dtype=float32), 'zero_points': array([-2], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 9, 'shape': array([1, 5], dtype=int32), 'shape_signature': array([-1,  5], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0119905471801758, -128), 'quantization_parameters': {'scales': array([1.0119905], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input details:\", input_details)\n",
    "print(\"Output details:\", output_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "844aa85e-a39e-494f-bff9-4873e01b908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scaler parameters\n",
    "scaler_params = np.load(\"scaler_params.npz\")\n",
    "mean = scaler_params[\"mean\"]\n",
    "scale = scaler_params[\"scale\"]\n",
    "\n",
    "# Example raw input\n",
    "sample_raw = np.array([[25.0, 50.0, 1000.0, 500.0]], dtype=np.float32)  # temp, humidity, pressure, gas_res\n",
    "\n",
    "# Scale input\n",
    "sample_scaled = (sample_raw - mean) / scale\n",
    "\n",
    "# For int8 quantized model, convert float to int8\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "sample_int8 = sample_scaled / input_scale + input_zero_point\n",
    "sample_int8 = sample_int8.astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45515860-fec7-4f0b-b3aa-99ba58d4223a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted gas values: [[ 27.323746 228.70987   24.287773  24.287773  17.203838]]\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0][\"index\"], sample_int8)\n",
    "interpreter.invoke()\n",
    "output_int8 = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "# Convert back to float\n",
    "output_scale, output_zero_point = output_details[0][\"quantization\"]\n",
    "output_float = (output_int8.astype(np.float32) - output_zero_point) * output_scale\n",
    "\n",
    "print(\"Predicted gas values:\", output_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac4ede97-8296-477c-9970-6aae2a8f032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted gas values: [[ 27.323746 228.70987   24.287773  24.287773  17.203838]]\n"
     ]
    }
   ],
   "source": [
    "# Load TFLite, scale input, run inference, print output\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"gas_model_int8.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load scaler\n",
    "scaler_params = np.load(\"scaler_params.npz\")\n",
    "mean = scaler_params[\"mean\"]\n",
    "scale = scaler_params[\"scale\"]\n",
    "\n",
    "# Sample input\n",
    "sample_raw = np.array([[25.0, 50.0, 1000.0, 500.0]], dtype=np.float32)\n",
    "sample_scaled = (sample_raw - mean) / scale\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "sample_int8 = (sample_scaled / input_scale + input_zero_point).astype(np.int8)\n",
    "\n",
    "# Run inference\n",
    "interpreter.set_tensor(input_details[0][\"index\"], sample_int8)\n",
    "interpreter.invoke()\n",
    "output_int8 = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "output_scale, output_zero_point = output_details[0][\"quantization\"]\n",
    "output_float = (output_int8.astype(np.float32) - output_zero_point) * output_scale\n",
    "\n",
    "print(\"Predicted gas values:\", output_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda3711-de9f-419c-b4d1-88c2d5089886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
